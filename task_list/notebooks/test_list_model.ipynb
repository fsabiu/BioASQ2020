{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello per le liste si basa sullo stesso modello utilizzato per le factoid provvediamo a importare il modello corretto e facciamo un test sul funzionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./embedding_models/biobert_factoid\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"./embedding_models/biobert_factoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['[CLS]', 'list', 'signaling', 'molecules', '(', 'l', '##igan', '##ds', ')', 'that', 'interact', 'with', 'the', 'receptor', 'e', '##g', '##f', '##r', '?', '[SEP]', 'the', 'e', '##pid', '##er', '##mal', 'growth', 'factor', 'receptor', '(', 'e', '##g', '##f', '##r', ')', 'l', '##igan', '##ds', ',', 'such', 'as', 'e', '##pid', '##er', '##mal', 'growth', 'factor', '(', 'e', '##g', '##f', ')', 'and', 'am', '##phi', '##re', '##gu', '##lin', '(', 'are', '##g', ')', '[SEP]']\n[101, 2190, 16085, 10799, 113, 181, 10888, 3680, 114, 1115, 12254, 1114, 1103, 10814, 174, 1403, 2087, 1197, 136, 102, 1103, 174, 25786, 1200, 7435, 3213, 5318, 10814, 113, 174, 1403, 2087, 1197, 114, 181, 10888, 3680, 117, 1216, 1112, 174, 25786, 1200, 7435, 3213, 5318, 113, 174, 1403, 2087, 114, 1105, 1821, 27008, 1874, 13830, 2836, 113, 1132, 1403, 114, 102]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
    }
   ],
   "source": [
    "question, text = \"List signaling molecules (ligands) that interact with the receptor EGFR?\", \"the epidermal growth factor receptor (EGFR) ligands, such as epidermal growth factor (EGF) and amphiregulin (AREG)\"\n",
    "encoding = tokenizer.encode_plus(question, text)\n",
    "input_ids, token_type_ids = encoding[\"input_ids\"], encoding[\"token_type_ids\"]\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(all_tokens)\n",
    "print(input_ids)\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-3.5126, -7.0865, -6.9067, -7.7472, -7.6168, -6.4265, -7.8138, -8.5346,\n         -8.5282, -7.4421, -7.2022, -7.1606, -7.4848, -8.1219, -7.4963, -7.8732,\n         -8.4675, -8.8533, -7.7126, -7.8307, -2.8615, -3.0179, -6.7289, -6.7677,\n         -6.4157, -6.0162, -6.7201, -4.8849, -4.4312, -5.3506, -7.3976, -7.3558,\n         -6.2990, -4.9410, -2.0951, -5.2530, -4.9682, -5.6626, -3.1414, -6.0405,\n         -0.9388, -7.2085, -7.6842, -6.7369, -5.8507, -6.5148, -5.1844, -4.1726,\n         -7.7461, -7.0326, -7.0507, -7.4014, -1.8171, -7.4988, -7.5553, -7.1843,\n         -5.8848, -5.8190, -6.7066, -7.4752, -6.2458, -7.8307]],\n       grad_fn=<SqueezeBackward1>)\ntensor([[-2.4085, -8.4290, -8.2037, -6.7629, -8.2680, -8.3713, -8.0804, -6.4559,\n         -7.4831, -8.3483, -8.1218, -8.0534, -8.5519, -7.9593, -8.7100, -8.3001,\n         -7.9757, -6.8480, -7.3486, -2.5235, -5.5465, -5.8049, -7.4287, -7.5961,\n         -7.3014, -6.4549, -4.0458, -2.8896, -5.6771, -8.3694, -8.4386, -8.0441,\n         -4.8070, -4.1241, -5.4386, -6.1758,  0.0400, -3.3661, -4.7527, -5.2686,\n         -6.2663, -8.5304, -8.7012, -8.2546, -6.9668, -2.9589, -6.2427, -8.1993,\n         -8.7458, -4.7270, -3.6925, -7.0831, -5.8833, -7.6268, -7.9693, -6.8034,\n         -0.4863, -7.1200, -9.0028, -3.6532, -1.8109, -2.5235]],\n       grad_fn=<SqueezeBackward1>)\ntensor(40)\ntensor(36)\n"
    }
   ],
   "source": [
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "print(torch.argmax(start_scores))\n",
    "print(torch.argmax(end_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    }
   ],
   "source": [
    "\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Answer: \"e\"\n"
    }
   ],
   "source": [
    "# Start with the first token.\n",
    "answer_start=torch.argmax(start_scores)\n",
    "answer_end=torch.argmax(end_scores)\n",
    "answer = all_tokens[answer_start]\n",
    "\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start + 1, answer_end + 1):\n",
    "    \n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if all_tokens[i][0:2] == '##':\n",
    "        answer += all_tokens[i][2:]\n",
    "    \n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += ' ' + all_tokens[i]\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-3.5126, -7.0865, -6.9067, -7.7472, -7.6168, -6.4265, -7.8138, -8.5346,\n         -8.5282, -7.4421, -7.2022, -7.1606, -7.4848, -8.1219, -7.4963, -7.8732,\n         -8.4675, -8.8533, -7.7126, -7.8307, -2.8615, -3.0179, -6.7289, -6.7677,\n         -6.4157, -6.0162, -6.7201, -4.8849, -4.4312, -5.3506, -7.3976, -7.3558,\n         -6.2990, -4.9410, -2.0951, -5.2530, -4.9682, -5.6626, -3.1414, -6.0405,\n         -0.9388, -7.2085, -7.6842, -6.7369, -5.8507, -6.5148, -5.1844, -4.1726,\n         -7.7461, -7.0326, -7.0507, -7.4014, -1.8171, -7.4988, -7.5553, -7.1843,\n         -5.8848, -5.8190, -6.7066, -7.4752, -6.2458, -7.8307]],\n       grad_fn=<SqueezeBackward1>)\ntensor([[-2.4085, -8.4290, -8.2037, -6.7629, -8.2680, -8.3713, -8.0804, -6.4559,\n         -7.4831, -8.3483, -8.1218, -8.0534, -8.5519, -7.9593, -8.7100, -8.3001,\n         -7.9757, -6.8480, -7.3486, -2.5235, -5.5465, -5.8049, -7.4287, -7.5961,\n         -7.3014, -6.4549, -4.0458, -2.8896, -5.6771, -8.3694, -8.4386, -8.0441,\n         -4.8070, -4.1241, -5.4386, -6.1758,  0.0400, -3.3661, -4.7527, -5.2686,\n         -6.2663, -8.5304, -8.7012, -8.2546, -6.9668, -2.9589, -6.2427, -8.1993,\n         -8.7458, -4.7270, -3.6925, -7.0831, -5.8833, -7.6268, -7.9693, -6.8034,\n         -0.4863, -7.1200, -9.0028, -3.6532, -1.8109, -2.5235]],\n       grad_fn=<SqueezeBackward1>)\ntensor([[40, 52, 34]])\ntensor([[36, 56, 60]])\n"
    }
   ],
   "source": [
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "values_start, indices_start=torch.topk(start_scores,3)\n",
    "values_end, indices_end=torch.topk(end_scores,3)\n",
    "print(indices_start)\n",
    "print(indices_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "l ##igan ##ds , such as e ##pid ##er ##mal growth factor ( e ##g ##f ) and am ##phi ##re ##gu\n"
    }
   ],
   "source": [
    "answer = ' '.join(all_tokens[34 : 56])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bert'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-dbf3b943e3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bert'"
     ]
    }
   ],
   "source": [
    "from bert import Ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}