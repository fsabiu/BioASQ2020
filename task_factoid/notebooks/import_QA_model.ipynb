{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging face for question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con modelli predefiniti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La libreria hugging face permette di importare modelli come faceva flair, questa libreria ha i metodi anche per impostare il modello direttamente oer il question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 369kB/s]\nDownloading: 100%|██████████| 1.34G/1.34G [14:26<00:00, 1.55MB/s]\n"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nelle seguenti linee si dichiarano la domanda e gli snippet e si generano le embeddings. In que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['[CLS]', 'who', 'is', 'mary', '?', '[SEP]', 'mary', 'is', 'a', 'br', '##illa', '##nt', 'student', 'in', 'rome', '[SEP]']\n[101, 2040, 2003, 2984, 1029, 102, 2984, 2003, 1037, 7987, 9386, 3372, 3076, 1999, 4199, 102]\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
    }
   ],
   "source": [
    "question, text = \"Who is Mary?\", \"Mary is a brillant student in Rome\"\n",
    "encoding = tokenizer.encode_plus(question, text)\n",
    "input_ids, token_type_ids = encoding[\"input_ids\"], encoding[\"token_type_ids\"]\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(all_tokens)\n",
    "print(input_ids)\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per questo primo esempio si da in pasto al modello la domanda in modo che possa calcolare i punteggi reativi a all'inizio di una risposta e alla fine di una risposta. Ci sarà un punteggio per ogni token in input e si prendono i massimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-5.0109, -5.9293, -6.8523, -2.9008, -8.2639, -5.0107,  0.6795, -3.0905,\n          4.8076,  3.5589, -3.9001, -4.0644, -1.2053, -2.7351,  0.3483, -5.0100]],\n       grad_fn=<SqueezeBackward1>)\ntensor([[ 0.1915, -6.0547, -6.0942, -2.1645, -5.8761,  0.1918, -0.7231, -4.6880,\n         -3.2773, -2.9547, -3.3409,  0.5081,  4.2771, -2.4325,  4.1675,  0.1900]],\n       grad_fn=<SqueezeBackward1>)\ntensor(8)\ntensor(12)\n"
    }
   ],
   "source": [
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "print(torch.argmax(start_scores))\n",
    "print(torch.argmax(end_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a br ##illa ##nt student\n"
    }
   ],
   "source": [
    "\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Answer: \"a brillant student\"\n"
    }
   ],
   "source": [
    "# Start with the first token.\n",
    "answer_start=torch.argmax(start_scores)\n",
    "answer_end=torch.argmax(end_scores)\n",
    "answer = all_tokens[answer_start]\n",
    "\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start + 1, answer_end + 1):\n",
    "    \n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if all_tokens[i][0:2] == '##':\n",
    "        answer += all_tokens[i][2:]\n",
    "    \n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += ' ' + all_tokens[i]\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test con importazione modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./embedding_models/biobert_factoid\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"./embedding_models/biobert_factoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['[CLS]', 'who', 'is', 'ma', '##ry', '?', '[SEP]', 'ma', '##ry', 'is', 'a', 'br', '##illa', '##nt', 'student', 'in', 'r', '##ome', '[SEP]']\n[101, 1150, 1110, 12477, 1616, 136, 102, 12477, 1616, 1110, 170, 9304, 5878, 2227, 2377, 1107, 187, 6758, 102]\n[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
    }
   ],
   "source": [
    "question, text = \"Who is Mary?\", \"Mary is a brillant student in Rome\"\n",
    "encoding = tokenizer.encode_plus(question, text)\n",
    "input_ids, token_type_ids = encoding[\"input_ids\"], encoding[\"token_type_ids\"]\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(all_tokens)\n",
    "print(input_ids)\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-3.2683, -4.1020, -7.0528, -3.5073, -7.0091, -6.8528, -1.2135,  1.1049,\n         -3.0018,  3.1927,  7.3026,  5.9603, -6.2884, -2.8307,  4.2421, -1.0523,\n          0.0679, -4.2151, -1.2135]], grad_fn=<SqueezeBackward1>)\ntensor([[-0.3841, -6.0075, -5.4050, -7.4030, -0.5038, -4.6372,  4.4007, -4.6523,\n          0.9098, -3.6444, -1.0526, -1.8325, -4.6182,  2.4971,  5.3820,  0.4778,\n         -0.3536,  1.9850,  4.4007]], grad_fn=<SqueezeBackward1>)\ntensor(10)\ntensor(14)\n"
    }
   ],
   "source": [
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "print(torch.argmax(start_scores))\n",
    "print(torch.argmax(end_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a br ##illa ##nt student\n"
    }
   ],
   "source": [
    "\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Answer: \"a brillant student\"\n"
    }
   ],
   "source": [
    "# Start with the first token.\n",
    "answer_start=torch.argmax(start_scores)\n",
    "answer_end=torch.argmax(end_scores)\n",
    "answer = all_tokens[answer_start]\n",
    "\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start + 1, answer_end + 1):\n",
    "    \n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if all_tokens[i][0:2] == '##':\n",
    "        answer += all_tokens[i][2:]\n",
    "    \n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += ' ' + all_tokens[i]\n",
    "\n",
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}