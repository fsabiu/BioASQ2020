{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tramite la libreria flair abbiamo la possibilità di accedere a delle word embeddings già trainate e che hanno riportato ottimi risultati in molti task NLP. In ogni caso è anche possibile utilizzare un proprio corpus, nel caso specifico di questa challenge l'hanno scorso hanno ottenuto scarsi risultati. Rispetto ad altre librerie si occupa solo di download e loading di embeddings in maniera facile e funzionale. A lezione abbiamo visto gensim è un altra libreria usata che permette la creazione di modelli(e quindi l'allenamento) tramite Word2Vec. Credo che se ci dobbiamo fermare solo all'importazione Flai è veramente facile ed essenziale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.embeddings import BertEmbeddings, ELMoEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding = BertEmbeddings()\n",
    "elmo_embedding = ELMoEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è inoltre possibile utilizzare più embeddings diverse assieme, avremo quindi una rappresentazione composta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_embeddings = StackedEmbeddings( embeddings = [bert_embedding,elmo_embedding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data una frase si può direttamente recuperare la rappresentazione tramite embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Sentence' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bcff0f1876d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Per me è la cipolla.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Sentence' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(\"Per me è la cipolla .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Sentence: \"Per me è la cipolla .\" - 6 Tokens]"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "bert_embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 0.2257, -0.1144,  0.9687,  ..., -0.4368, -1.4103,  0.7699])\ntensor([-0.2913, -0.5873,  1.0522,  ..., -0.2258, -1.3292,  1.9042])\ntensor([-0.5470, -0.6897,  1.5028,  ..., -0.0881, -1.5068,  0.6295])\ntensor([-0.7008, -0.7486,  1.1706,  ...,  0.1754, -0.8344,  0.3649])\ntensor([ 0.0383, -0.9000,  1.2285,  ..., -0.6177, -0.4589,  1.2688])\ntensor([-0.6100, -0.6452,  0.6590,  ..., -0.0245, -0.7642,  0.0216])\n"
    }
   ],
   "source": [
    "for token in sentence:\n",
    "  print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se invece si vuole usare un modello non incluso nella libreria come biobert o elmopubmed si scarica e si importa come descrito sotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Sentence: \"Ah che bello nlp!!!\" - 4 Tokens]"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "sentence = Sentence('Ah che bello nlp!!!')\n",
    "\n",
    "# init embeddings from your trained LM\n",
    "my_fantastic_embeddings = BertEmbeddings('./biobert_v1.1_pubmed')\n",
    "\n",
    "# embed sentence\n",
    "my_fantastic_embeddings.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 0.1548, -0.3745, -0.0815,  ...,  0.8736, -0.1315, -0.0639])\ntensor([-0.1636,  0.2026,  0.4898,  ...,  0.8701, -0.0799, -0.8752])\ntensor([-0.4372,  0.3427,  0.6304,  ..., -0.6638, -0.7695, -0.5325])\ntensor([ 0.4190, -0.7349,  0.3543,  ...,  1.3157,  0.2120, -0.6315])\n"
    }
   ],
   "source": [
    "for token in sentence:\n",
    "  print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I modelli che si trovano online non tutti sono realizzati con pytorch di conseguenza sono necessari degli adattamenti, per permettere la lettuar con pytorch (Libreria di machine learning utilizzata da Flair).\n",
    "Il particolare per il modello biobert sono stati necessati i seguenti comandi:\n",
    "* <code>pytorch_transformers bert biobert_v1.1_pubmed/model.ckpt-1000000 biobert_v1.1_pubmed/bert_config.json biobert_v1.1_pubmed/pytorch_model.bin</code>\n",
    "* Rinominare bert_config.json in config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}